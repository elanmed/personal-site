---
title: "Freeing Neovim's UI with batching"
abstract: "Template abstract"
lastUpdated: "December 21, 2025"
slug: freeing-neovims-ui-with-batching
tags:
  - software eng
  - vim
collection: null
isPublished: false
---

When building a process-intensive Neovim plugin, one of the first things you'll encounter is UI
freezes. It's frustrating, but it makes sense - Neovim can't update the UI with the latest typed
keystrokes while

## Boilerplate

To start, let's set up some boilerplate to experience some UI freezing first hand:

```lua
local enter_win = true
local listed_buf = false
local scratch_buf = true
local strict_indexing = false

local results_bufnr = vim.api.nvim_create_buf(listed_buf, scratch_buf)
local results_winnr = vim.api.nvim_open_win(results_bufnr, not enter_win, {
  split = "right",
  win = 0,
})

local input_bufnr = vim.api.nvim_create_buf(listed_buf, scratch_buf)
local input_winnr = vim.api.nvim_open_win(input_bufnr, enter_win, {
  split = "above",
  win = results_winnr,
})

vim.api.nvim_win_set_height(input_winnr, 1)

vim.api.nvim_create_autocmd("WinClosed", {
  pattern = { tostring(input_winnr), tostring(results_winnr), },
  callback = function()
    local force_close = true
    if vim.api.nvim_win_is_valid(input_winnr) then vim.api.nvim_win_close(input_winnr, force_close) end
    if vim.api.nvim_win_is_valid(results_winnr) then vim.api.nvim_win_close(results_winnr, force_close) end
  end,
})

--- @param input string
local function populate_results(input)
  -- TODO
end

vim.api.nvim_create_autocmd({ "TextChanged", "TextChangedI", }, {
  buffer = input_bufnr,
  callback = function()
    local input = vim.api.nvim_buf_get_lines(input_bufnr, 0, 1, strict_indexing)
    populate_results(input[1] or "")
  end,
})
```

This code creates an input buffer, results buffer, windows for each, and sets up two autocommands.
The first is just for convenience: when closing either the input or results window, the other is
closed as well. The second is more relevant: when the input buffer changes, a `populate_results`
function will run.

Let's start by creating a large table (think the results from `fd`) and looping over the table to
populate the results buffer:

```lua
local large_tbl = {}
for i = 1, 100000 do
  table.insert(large_tbl, i)
end

-- ...

--- @param input string
local function populate_results(input)
  local results = {}
  for _, entry in ipairs(large_tbl) do
    table.insert(results, ("%d :: %s"):format(entry, input))
  end

  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end
```

You'll notice that the UI freezes while typing - the entire loop needs to complete before Neovim can
yield back to the main thread to update the UI with the latest keystroke. Looping a hundred thousand
times might seem a bit contrived, but I've run into this scenario several times when processing
results from commands such as `fd` and `rg`. So, how can we free up the UI?

## Batches

A simple solution is to process the loop with batches, allowing the UI to update between each. A
simple batcher function could look like the following:

```lua
--- @generic T
--- @param list T[]
--- @param on_iteration fun(entry: T):nil
--- @param on_complete fun():nil
--- @param batch_size? number
local function list_batcher(list, on_iteration, on_complete)
  batch_size = batch_size or 100

  local step
  --- @param start number
  step = function(start)
    for i = start, math.min(#list, start + batch_size - 1) do
      on_iteration(list[i])
    end
    start = start + batch_size
    if start > #list then
      on_complete()
    else
      vim.schedule(function() step(start) end)
    end
  end
  step(1)
end
```

With it's invocation:

```lua
--- @param input string
local function populate_results(input)
  local results = {}
  list_batcher(
    large_tbl,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end,
    function()
      vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
    end
  )
end
```

This works for looping over tables, but how about traversing other iterators? For example, the
`vim.fs.dir(path)` returns an iterator over the items in its path argument, and our `batcher`
wouldn't be able to handle it at all.

## A more generic iterator

A quick crash course on iterators in lua:

- An iterator is a function that returns the next element in a collection on every invocation.
- Iterators are normaly returned by calling another function: an iterator factory. `ipairs(table)`
  is an example of an iterator factory
- Calling the iterator factory returns up to three values:
  1. The iterator function
  2. The "invariant state"
  3. The initial value of the "control variable"
- The iterator function is called with the invariant state and the control variable
- If the first value returned by the iterator is `nil`, the iteration should end. Otherwise, the
  control variable is set to the first value returned by the other, and the iterator is called again
  with the (static) invariant state and the updated control variable

The names are a bit academic, but I generally think its best to use the nomenclature in the
documentation rather than make something up myself.

The implementation uses some generics for clarity, but the code itself is still straightforward.

```lua
--- @generic IterState, IterVar
--- @param iterator_factory fun(): fun(invariant_state: IterState, control_var: IterVar):IterVar, IterState, IterVar
--- @param on_iteration fun(entry: IterVar):nil
--- @param on_complete fun():nil
--- @param batch_size? number
local function iterator_batcher(iterator_factory, on_iteration, on_complete)
  batch_size = batch_size or 100

  local iter_fn, invariant_state, control_var = iterator_factory()
  local step
  step = function()
    local num_processed = 0
    while num_processed < batch_size do
      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
      num_processed = num_processed + 1
    end
    vim.schedule(step)
  end
  step()
end

--- @param input string
local function populate_results(input)
  local results = {}
  iterator_batcher(
    function() return ipairs(large_tbl) end,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end,
    function()
      vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
    end
  )
end
```

## Basic async-await with coroutines

Our `iterator_batcher` looks solid, but Javascript developers will recognize the potential for
callback-hell: nesting another `iterator_batcher` within an `on_complete` can lead to some very
nested and messy code very quickly. How can we "await" batching to avoid an `on_complete` callback?
Coroutines!

The core of this approach uses three functions: `async`, `await`, and a `promise` - I work in web
development, so this is the pattern I'm most comfortable with.

The `promise` will be a function that performs the async action and accepts a `resolve` argument:

Let's start with a classic timer example:

```lua
local function main()
  vim.print "start"
  vim.fn.timer_start(2000, function()
    vim.print "timer callback"
  end)
  vim.print "end"
end
main()

-- start
-- end
-- timer callback
```

How can we promisify this so that the order becomes `start` -> `timer callback` -> `end`. In
javascript, we would create a promise that resolves in the callback - let's follow the same pattern.

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

local function main()
  vim.print "start"
  await promise -- how can we mimic this syntax?
  vim.print "timer callback"
  vim.print "end"
end
main()
```

I often find it helpful to go in reverse order: start with the interface I'd like to work with and
then figure out how to build it. So, how can we mimic an `await`? This next section is a bit of a
jump, but bear with me:

```lua
--- @param promise fun(resolve: fun():nil):nil
local await = function(promise)
  local thread = coroutine.running()
  assert(thread ~= nil, "`await` can only be called in a coroutine")
  local scheduled_promise = vim.schedule_wrap(promise)
  scheduled_promise(function() coroutine.resume(thread) end)
  coroutine.yield()
end
```

`await` is going to be a function which takes in our promise. The promise is going to be called
_with_ `resolve` immediately, but the promise will only call the resolve function _itself_ when the
async task is finished. This is where the coroutine magic comes into play: because we're wrapping
the `promise` function call in a `schedule_wrap`, it will only be _scheduled_ to run when
`scheduled_promise` is called - `coroutine.yield()` will be called before `scheduled_promise` is.
`coroutine.yield()` pauses execution until the next `coroutine.resume` - which is our `resolve`
function that's called when the async task completes!

That gives us this code in `main`:

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

local function main()
  vim.print "start"
  await(promise)
  vim.print "timer callback"
  vim.print "end"
end
main()
```

But one last part: our `await` assumes that it's called in the context of a coroutine - but we have
no coroutine in `main`. A one-off approach would be to replace `main()` with:

```lua
coroutine.resume(coroutine.create(main))
```

But this has a big drawback: errors thrown in `main` are silently swallowed! This is where `async`
comes into play:

```lua
--- @param fn fun():nil
local async = function(fn)
  return function(...)
    local ok, err = coroutine.resume(coroutine.create(fn), ...)
    if not ok then error(err) end
  end
end
```

Updating `main`, that gives us:

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

local main = async(function()
  vim.print "start"
  await(promise)
  vim.print "timer callback"
  vim.print "end"
end)
main()
```

## Bonus: A class-based approach

I'm personally a fan of the builder pattern, so I prefer to use a class-based batcher function like
the following:

```lua
local Batch = {}
Batch.__index = Batch

--- @generic IterState, IterVar
--- @param iter_factory fun(): ((fun(invariant_state: IterState, control_var: IterVar):IterVar), IterState, IterVar)
function Batch:new(iter_factory)
  local this = {
    _iter_factory = iter_factory,
    _size = math.huge,
  }

  setmetatable(this, Batch)
  return this
end

--- @param size number
function Batch:size(size)
  self._size = size
  return self
end

--- @generic T
--- @param on_iteration fun(entry: T):nil
--- @param on_complete fun():nil
function Batch:each(on_iteration, on_complete)
  local iter_fn, invariant_state, control_var = self._iter_factory()
  local step
  step = function()
    local num_processed = 0
    while num_processed < self._size do
      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
      num_processed = num_processed + 1
    end
    vim.schedule(step)
  end
  step()
end

local main = async(function()
  local promise = function(resolve)
    Batch
        :new(function() return ipairs(list) end)
        :size(2)
        :each(
          function(entry) print(entry) end,
          resolve
        )
  end
  await(promise)
end)
main()
```
