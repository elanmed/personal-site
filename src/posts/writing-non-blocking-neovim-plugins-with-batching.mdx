---
title: "Writing Non-Blocking Neovim Plugins"
abstract: "Prevent UI freezes using batched iteration and coroutine-based async-await"
lastUpdated: "January 03, 2026"
slug: writing-non-blocking-neovim-plugins-with-batching
tags:
  - software eng
  - vim
collection: null
isPublished: true
---

# Writing Non-Blocking Neovim Plugins

When building a process-intensive Neovim plugin, one of the first things you'll encounter is an
unresponsive editor: since Neovim's Lua runtime is single threaded, the UI can't update while
something else is running on the main thread. Thankfully, with a bit of batching and coroutines, we
can prevent the editor from hanging while maintaining a developer-friendly interface.

## Boilerplate

To start, let's set up some boilerplate to experience an unresponsive editor first hand:

```lua
local enter_win = true
local listed_buf = false
local scratch_buf = true
local strict_indexing = false

local results_bufnr = vim.api.nvim_create_buf(listed_buf, scratch_buf)
local results_winnr = vim.api.nvim_open_win(results_bufnr, not enter_win, {
  split = "right",
  win = 0,
})

local input_bufnr = vim.api.nvim_create_buf(listed_buf, scratch_buf)
local input_winnr = vim.api.nvim_open_win(input_bufnr, enter_win, {
  split = "above",
  win = results_winnr,
})

vim.api.nvim_win_set_height(input_winnr, 1)

vim.api.nvim_create_autocmd("WinClosed", {
  pattern = { tostring(input_winnr), tostring(results_winnr), },
  callback = function()
    local force_close = true
    if vim.api.nvim_win_is_valid(input_winnr) then vim.api.nvim_win_close(input_winnr, force_close) end
    if vim.api.nvim_win_is_valid(results_winnr) then vim.api.nvim_win_close(results_winnr, force_close) end
  end,
})

--- @param input string
local function populate_results(input)
  -- TODO
end

vim.api.nvim_create_autocmd({ "TextChanged", "TextChangedI", }, {
  buffer = input_bufnr,
  callback = function()
    local input = vim.api.nvim_buf_get_lines(input_bufnr, 0, 1, strict_indexing)
    populate_results(input[1] or "")
  end,
})
```

This code creates an input buffer, results buffer, windows for each, and sets up two autocommands.
The first is just for convenience: when closing either the input or results window, the other is
closed as well. The second is more relevant: when the input buffer changes, a `populate_results`
function will run.

Let's start by creating a large table and looping over it to populate the results buffer:

```lua
local large_tbl = {}
for i = 1, 100000 do
  table.insert(large_tbl, i)
end

-- ...

--- @param input string
local function populate_results(input)
  local results = {}
  for _, entry in ipairs(large_tbl) do
    table.insert(results, ("%d :: %s"):format(entry, input))
  end

  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end
```

You'll notice that the UI freezes while typing - the entire loop needs to complete before Neovim can
update the UI with the latest keystroke. Looping a hundred thousand times might seem a bit
contrived, but I've run into this scenario several times when processing results from commands such
as `fd` and `rg`. How do we fix this?

## Batching part 1: the basics

The first solution we'll look at is batching: break the loop into chunks, process one chunk at a
time, and schedule the next chunk after each UI update.

A simple implementation could look like:

```lua
--- @generic T
--- @param list T[]
--- @param on_iteration fun(entry: T):nil
--- @param on_complete fun():nil
--- @param batch_size_inclusive? number
local function list_batcher(list, on_iteration, on_complete, batch_size_inclusive)
  batch_size_inclusive = batch_size_inclusive or 100

  local step
  --- @param start number
  step = function(start)
    for i = start, math.min(#list, start + batch_size_inclusive - 1) do
      on_iteration(list[i])
    end
    start = start + batch_size_inclusive
    if start > #list then
      on_complete()
    else
      vim.schedule(function() step(start) end)
    end
  end
  step(1)
end
```

And its invocation:

```lua
--- @param input string
local function populate_results(input)
  local results = {}
  list_batcher(
    large_tbl,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end,
    function()
      vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
    end
  )
end
```

This works for looping over tables, but how about traversing other iterators? For example, the
`vim.fs.dir(path)` returns an iterator over the items in its path argument - in its current form,
our batcher wouldn't be able to handle it.

## Batching part 2: handling generic iterators

A quick crash-course on iterators in Lua (based on the official
[docs](https://www.lua.org/pil/7.1.html)):

- An iterator is a function that returns the next element in a collection on every invocation
- Iterators are normally returned by calling another function: an iterator factory. `ipairs(table)`
  is an example of an iterator factory
- Calling the iterator factory returns (up to) three values:
  1. The iterator function
  2. The "invariant state"
  3. The initial value of the "control variable"
- The iterator function is called with the invariant state and the control variable
- If the first value returned by the iterator function is `nil`, the iteration should end.
  Otherwise, the control variable is set to the first value returned by the iterator function, and
  the iterator is called again with the (static) invariant state and the (updated) control variable

The names are a bit academic, but I prefer to use the nomenclature in the documentation rather than
make something up myself.

The implementation below uses several generic types for clarity, but that can be skipped - the code
itself is the same either way.

```lua
--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @param on_iteration fun(entry: ControlVar):nil
--- @param on_complete fun():nil
--- @param batch_size_inclusive? number
local function iterator_batcher(iterator_factory, on_iteration, on_complete, batch_size_inclusive)
  batch_size_inclusive = batch_size_inclusive or 100

  local iter_fn, invariant_state, control_var = iterator_factory()
  local step
  step = function()
    local num_processed = 0
    while num_processed < batch_size_inclusive do
      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
      num_processed = num_processed + 1
    end
    vim.schedule(step)
  end
  step()
end

--- @param input string
local function populate_results(input)
  local results = {}
  iterator_batcher(
    function() return ipairs(large_tbl) end,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end,
    function()
      vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
    end
  )
end
```

## Interlude: basic async-await with coroutines

Our `iterator_batcher` looks solid, but JavaScript developers will recognize the potential for
callback-hell: adding a nested `iterator_batcher` within an `on_complete` can lead to some very
indented and hard-to-read code. Instead, how can we "await" the batching in order to perform some
work which relies on the batching to complete, while also avoiding an `on_complete` callback?

The core of this solution uses three functions: `async`, `await`, and a `promise` - I work in web
development, so this is the pattern I'm most comfortable with.

Let's start with a classic timer example:

```lua
local function main()
  vim.print "start"
  vim.fn.timer_start(2000, function()
    vim.print "timer callback"
  end)
  vim.print "end"
end
main()

-- prints:
-- start
-- end
-- timer callback
```

How can we update the code so that the printed order becomes `start` -> `timer callback` -> `end`.
In JavaScript, we would create a promise that's resolved in the timer's callback:

```js
const promise = new Promise((resolve) => {
  setTimeout(() => {
    resolve();
  }, 2000);
});

async function main() {
  console.log("start");
  await promise;
  console.log("timer callback");
  console.log("end");
}
main();

// logs:
// start
// timer callback
// end
```

Let's try to follow the same pattern.

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

-- how can we create this syntax?
async local function main()
  vim.print "start"
  await promise -- and this?
  vim.print "timer callback"
  vim.print "end"
end
main()
```

What we want from `await` is to begin executing the promise, pause, resume when the async action in
the promise is complete, and continue on. Using coroutines, we can achieve this with just a few more
lines of code than with JavaScript.

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

--- @param promise fun(resolve: fun():nil):nil
local await = function(promise)
  local thread = coroutine.running()
  local resume_callback = function() coroutine.resume(thread) end
  promise(resume_callback)
  coroutine.yield()
end

local function main()
  vim.print "start"
  await(promise)
  vim.print "timer callback"
  vim.print "end"
end
coroutine.resume(coroutine.create(main))
vim.print "after resume"

-- prints:
-- start
-- after resume
-- timer callback
-- end
```

Let's walk through the execution of this code:

- A coroutine is created with the function `main` and immediately resumed
- `"start"` is printed
- `await` is called with `promise`
- `promise` is called, triggering the 2 second timer and scheduling `resume_callback` to be called
  at the end of the timer
- `coroutine.yield()` pauses the coroutine running `main`
- `"after resume"` is printed
- 2 seconds pass, triggering the callback passed to `timer_start` - which calls `resume_callback`
- `resume_callback` calls `coroutine.resume()`, which resumes the coroutine that's running `main`
- `"timer callback"` is printed
- `"end"` is printed

Notice that `await` assumes that it's called in the context of a coroutine (i.e. it uses
`coroutine.running`), which is why the code above wraps `main` in a `coroutine.resume` and
`coroutine.create`. However this code has a flaw: errors thrown in `main` are silently swallowed!
Try running this snippet:

```lua
local function main()
  error "Swallowed!"
end
coroutine.resume(coroutine.create(main))
```

This is where a dedicated `async` comes into play:

```lua
--- @param fn fun(...):nil
local async = function(fn)
  return function(...)
    local ok, err = coroutine.resume(coroutine.create(fn), ...)
    if not ok then error(err) end
  end
end
```

Updating `main`, that gives us:

```lua
local function promise(resolve)
  vim.fn.timer_start(2000, resolve)
end

local main = async(function()
  vim.print "start"
  await(promise)
  vim.print "timer callback"
  vim.print "end"
end)
main()
```

---

One downside of the current `await` function is that it assumes that `resume_callback` isn't called
immediately i.e. if it was called immediately, then the coroutine would _first_ resume _then_
yield - with nothing to resume the paused coroutine afterwards! A safer approach is to wrap
`promise` in `vim.schedule_wrap`, which you can think of as a `timer_start` with a timeout of `0`:

```lua
--- @param promise fun(resolve: fun():nil):nil
local await = function(promise)
  local thread = coroutine.running()
  assert(thread ~= nil, "`await` can only be called in a coroutine")
  local scheduled_promise = vim.schedule_wrap(promise)
  local resume_callback = function() coroutine.resume(thread) end
  scheduled_promise(resume_callback)
  coroutine.yield()
end
```

## Batching part 3: async-await

Back to our batcher function, we can use `async` and `await` to set the results buffer at the same
level of indentation as the `iterator_batcher`:

```lua
local populate_results = async(function(input)
  local results = {}
  local promise = function(resolve)
    iterator_batcher(
      function() return ipairs(large_tbl) end,
      function(entry)
        table.insert(results, ("%d :: %s"):format(entry, input))
      end,
      resolve
    )
  end
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

Or a bit more reusable:

```lua
--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @param on_iteration fun(entry: ControlVar):nil
--- @param batch_size_inclusive? number
local function async_iterator_batcher(iterator_factory, on_iteration, batch_size_inclusive)
  return function(resolve)
    iterator_batcher(iterator_factory, on_iteration, resolve, batch_size_inclusive)
  end
end

local populate_results = async(function(input)
  local results = {}
  local promise = async_iterator_batcher(
    function() return ipairs(large_tbl) end,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end
  )
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

## An alternative to batching: time-based yielding

An alternative to batching is to simply pause execution every `n` milliseconds - an approach
inspired by [`mini.pick`](https://github.com/nvim-mini/mini.pick).

In this solution we'll support generic iterators as before, but use coroutines internally to
occasionally pause and resume in a `vim.schedule`.

```lua
--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @param on_iteration fun(entry: ControlVar):nil
--- @param on_complete fun():nil
local function iterator_throttled(iterator_factory, on_iteration, on_complete)
  local threshold_ns = 10 * 1000000

  local function create_throttle()
    local last_yield = vim.loop.hrtime()
    return function()
      local now = vim.loop.hrtime()
      if (now - last_yield) >= threshold_ns then
        last_yield = now
        local thread = coroutine.running()
        vim.schedule(function() coroutine.resume(thread) end)
        coroutine.yield()
      end
    end
  end

  local function process()
    local maybe_pause = create_throttle()

    local iter_fn, invariant_state, control_var = iterator_factory()
    while true do
      maybe_pause()

      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
    end
  end

  local promise = async(process)
  promise()
end
```

The main advantage of `iterator_throttled` over `iterator_batcher` is that `iterator_throttled` is
hardware-independent. `iterator_batcher` yields every `n` batches, regardless of how long those
batches take to process on the machine in question. 10 nanoseconds, on the other hand, is always 10
nanoseconds.

For completeness, here's an `async_iterator_batcher` and its invocation:

```lua
--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @param on_iteration fun(entry: ControlVar):nil
local function async_iterator_throttled(iterator_factory, on_iteration)
  return function(resolve)
    iterator_throttled(iterator_factory, on_iteration, resolve)
  end
end

local populate_results = async(function(input)
  local results = {}
  local promise = async_iterator_throttled(
    function() return ipairs(large_tbl) end,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end
  )
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

For completeness, an `async_iterator_batcher` and its invocation:

```lua
--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @param on_iteration fun(entry: ControlVar):nil
local function async_iterator_throttled(iterator_factory, on_iteration)
  return function(resolve)
    iterator_throttled(iterator_factory, on_iteration, resolve)
  end
end

local populate_results = async(function(input)
  local results = {}
  local promise = async_iterator_throttled(
    function() return ipairs(large_tbl) end,
    function(entry)
      table.insert(results, ("%d :: %s"):format(entry, input))
    end
  )
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

## Cancellation

## Bonus: A class-based approaches

I'm personally a fan of the builder pattern, so I prefer to use class-based functions like the
following:

```lua
--- @class Batch
--- @field _iterator_factory fun(): ((fun(invariant_state: any, control_var: any):any), any, any)
--- @field _batch_size_inclusive number
local Batch = {}
Batch.__index = Batch

--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @return Batch
function Batch:new(iterator_factory)
  local this = {
    _iteratory_factory = iterator_factory,
    _batch_size_inclusive = math.huge,
  }

  setmetatable(this, Batch)
  return this
end

--- @param size number
--- @return Batch
function Batch:size(size)
  self._batch_size_inclusive = size
  return self
end

--- @generic T
--- @param on_iteration fun(entry: T):nil
--- @param on_complete fun():nil
--- @return nil
function Batch:each(on_iteration, on_complete)
  local iter_fn, invariant_state, control_var = self._iteratory_factory()
  local step
  step = function()
    local num_processed = 0
    while num_processed < self._batch_size_inclusive do
      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
      num_processed = num_processed + 1
    end
    vim.schedule(step)
  end
  step()
end

--- @generic T
--- @param on_iteration fun(entry: T):nil
--- @return fun(resolve: fun():nil):nil
function Batch:each_async(on_iteration)
  return function(resolve) self:each(on_iteration, resolve) end
end

local populate_results = async(function(input)
  local results = {}
  local promise = Batch
      :new(function() return ipairs(large_tbl) end)
      :size(100)
      :each_async(function(entry)
        table.insert(results, ("%d :: %s"):format(entry, input))
      end)
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

Or:

```lua
--- @class Throttle
--- @field _iterator_factory fun(): ((fun(invariant_state: any, control_var: any):any), any, any)
--- @field _threshold_ns number
local Throttle = {}
Throttle.__index = Throttle

--- @generic InvariantState, ControlVar
--- @param iterator_factory fun(): ((fun(invariant_state: InvariantState, control_var: ControlVar):ControlVar), InvariantState, ControlVar)
--- @return Throttle
function Throttle:new(iterator_factory)
  local ns_10 = 10 * 1000000
  local this = {
    _iterator_factory = iterator_factory,
    _threshold_ns = ns_10,
  }

  setmetatable(this, Throttle)
  return this
end

--- @param threshold_ns number
--- @return Throttle
function Throttle:threshold_ns(threshold_ns)
  self._threshold_ns = threshold_ns
  return self
end

--- @generic T
--- @param on_iteration fun(entry: T):nil
--- @param on_complete fun():nil
--- @return nil
function Throttle:each(on_iteration, on_complete)
  local function create_throttle()
    local last_yield = vim.loop.hrtime()
    return function()
      local now = vim.loop.hrtime()
      if (now - last_yield) >= self._threshold_ns then
        last_yield = now
        local thread = coroutine.running()
        vim.schedule(function() coroutine.resume(thread) end)
        coroutine.yield()
      end
    end
  end

  local function process()
    local maybe_pause = create_throttle()

    local iter_fn, invariant_state, control_var = self._iterator_factory()
    while true do
      maybe_pause()

      local values = { iter_fn(invariant_state, control_var), }
      control_var = values[1]

      if control_var == nil then
        on_complete()
        return
      end

      on_iteration(unpack(values))
    end
  end

  local promise = async(process)
  promise()
end

--- @generic T
--- @param on_iteration fun(entry: T):nil
--- @return fun(resolve: fun():nil):nil
function Throttle:each_async(on_iteration)
  return function(resolve) self:each(on_iteration, resolve) end
end

local populate_results = async(function(input)
  local results = {}
  local promise = Throttle
      :new(function() return ipairs(large_tbl) end)
      :threshold_ns(10)
      :each_async(function(entry)
        table.insert(results, ("%d :: %s"):format(entry, input))
      end)
  await(promise)
  vim.api.nvim_buf_set_lines(results_bufnr, 0, -1, strict_indexing, results)
end)
```

Thanks for reading.
